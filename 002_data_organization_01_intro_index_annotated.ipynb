{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "print(pd.__version__)\n",
    "\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# `Series`\n",
    "`Series` is a data type implemented by `pandas` package. It combines numerical speed on `numpy` and dictinary-like indexing. `Series` are always 1-dimensional, and they have 2 elements -- `index` and `value`. Let's create a `Series` as an example. We can create it in a same way as we would a `numpy` array:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data = pd.Series([0.25, 0.5, 0.75, 1.0, 1.25, 1.5])\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As it stands, it doesn't seem to be much different from `numpy` array, and we can access the values (right column) in the same way as with `numpy` array, using `index` (the left column):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data[3:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also extract `values` and `index` separately:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# values are represented as numpy array\n",
    "data.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# index in this case is a range object\n",
    "data.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# we can change it to a list or array\n",
    "np.array(data.index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So far, it is unclear why we would use `Series` over arrays. First, index doesn't need to be integer. Here I create a `Series` where index is `str` rather than numbers. To do it, I specify `index` explicitly when I create the `Series`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data = pd.Series([0.25, 0.5, 0.75, 1.0, 1.25, 1.5],\n",
    "                 index=['a', 'b', 'c', 'd', 'e', 'f'])\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can access the values in a way that is more reminiscent of `dict`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data['b']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But compared to `dict` we can also slice things in the `Series`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data['b':'e']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can think of `Series` as an array which has its own index associates with it, which can be anything you want. And you can access the values in the `Series` based on that index. This entails many convenient properties, for example, if you select a subset of the `Series`, the index will be preserved:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# create Series with values from 10 to 12 with step 0.1 using numpy function arange\n",
    "data = pd.Series(np.arange(10,12,0.1))\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# take every second value from that Series; note that the index is preserved\n",
    "data[::2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is extremely useful when working with data, because you don't need to worry about which subset of data you've picked: indexes will be always consistent. In reality, `pandas` gives you choice: you can access elements based on the index associated with these elements (*explicit* index) and based on the position of the element independent of the index (*implicit* index, same as with `numpy` arrays)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`Series` are also extremely useful when you have labels for each values, like so: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "population_dict = {'California': 38332521,\n",
    "                   'Texas': 26448193,\n",
    "                   'New York': 19651127,\n",
    "                   'Florida': 19552860,\n",
    "                   'Illinois': 12882135}\n",
    "population = pd.Series(population_dict)\n",
    "population"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we created the `Series` from `dict`, and you could say -- why would we even use `Series` here when we already have `dict` with the same content?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# you can access dict\n",
    "population_dict['California']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# and you can access Series in the same way\n",
    "population['California']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The answer is twofold. First, efficiency. `Series` give you efficiency of `numpy` arrays, when you use them for computation. `dicts` lack this efficiency (they are optimized for a specific purpose). Second, `Series` offer more flexibility in working with data, like doing slices:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "population['California':'Illinois']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ways to create `Series`\n",
    "There are many ways you can create `Series`, here are some:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pd.Series([2, 4, 6])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pd.Series(5, index=[100, 200, 300])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pd.Series({2:'a', 1:'b', 3:'c'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <font color='DarkSeaGreen '>Exercise</font>\n",
    "In the cell(s) below:\n",
    "1. Create a `Series` with the following content: `index` are numbers from 1 to 7 (use `np.arange` to create that). Values are strings, containing names of the days of the week from Monday to Sunday. \n",
    "\n",
    "2. Create another `Series` with the same `index`, but values are 'Workday' for indexes 1 to 5 and 'Weekend' for 6 and 7.\n",
    "\n",
    ">**Tip**: try this and see what it does: `['Workday']*5`\n",
    "\n",
    ">**Tip**: try this and see what it does: `['a','b','c'] + ['d','e']`\n",
    "\n",
    "Optional:\n",
    "1. Create a `Series` with the following content: `index` are days of the month April 2017 (from 1 to 30), and values are days of the week are numbers from 1 to 7 (1st of April was Saturday). \n",
    "\n",
    "2. Create another `Series` with the same index, and names of the days of the week. Try to use your previous `Series` with days of the week to populate the `Series` with names of the days.\n",
    "\n",
    "3. Create another `Series` with the same index, but fill it with strings 'Workday' and 'Weekend'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# `DataFrame`\n",
    "`Series` are good and useful and all, but frequently we have not a single dimension, but a collection of associated variable, like, for example, names of subjects, their age, their score on our task, etc. `DataFrame` is a multidimensional extension of `Series`. It has *rows*, just like `Series`, but it also has *columns*. Let's create a `DataFrame` from a `Series` with state populations we had before, and add area of each state as a second column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "area_dict = {'California': 423967, 'Texas': 695662, 'New York': 141297,\n",
    "             'Florida': 170312, 'Illinois': 149995}\n",
    "area = pd.Series(area_dict)\n",
    "area"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "states = pd.DataFrame({'population': population,\n",
    "                       'area': area})\n",
    "states"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the `DataFrame` index is shared between all columns:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "states.index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can also get a list of all columns:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "states.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And each column is a `Series`, which you can access with `dict`-like notation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "states['area']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# verify that a single columns of a dataframe is a series\n",
    "type(states['area'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ways to construct `DataFrame`\n",
    "As with `Series`, there are many ways of creating `DataFrames`, here are some:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pd.DataFrame(population, columns=['population'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pd.DataFrame([{'a': 1, 'b': 2}, {'b': 3, 'c': 4}])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "states = pd.DataFrame({'population': population,\n",
    "                       'area': area})\n",
    "states"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pd.DataFrame(np.random.rand(3, 2),\n",
    "             columns=['foo', 'bar'],\n",
    "             index=['a', 'b', 'c'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <font color='DarkSeaGreen '>Exercise</font>\n",
    "In the cell(s) below:\n",
    "1. Create a `DataFrame` from the 2 `Series` in the previous exercise with one column holding names of days of the week and another holding whether it is a workday or a weekend. \n",
    "\n",
    "Optional:\n",
    "1. Do the same for your `Series` with days of the month (you'll have 3 columns: number of the day of the week, name of the day of the week and whether it is workday or a weekend)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Indexing and selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The point of `index` is, well... indexing. That is, `index` is a basically just a column by which is it handy to *idenfity* individual rows. If you think about `index` in this way, it becomes apparent, for example, that `index` should not contain duplicates (it can, but it is usually not a good idea, because trying to get a single value will give you several values)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data = pd.Series([0.25, 0.5, 0.75, 1.0],\n",
    "                 index=['a', 'b', 'c', 'd'])\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data['b']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As I was saying, `Series` (and `DataFrames`) combine the functionality of `dict` and `numpy` arrays, and `Series` allow you to use many methods from both of these classes. For example, while you can access index of the `Series` by using `Series.index` attribute, you can also use method `keys()` which come straight from the `dict` class, and it will give the same output. After all, `index` for `Series` is like `key` for `dict`: these are the \"hooks\" which allow you to get certain values from the objects."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can add new values to the `Series` just like you would to the `dict`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data['e'] = 1.25\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Slicing and indexing\n",
    "Slicing and indexing `Series` and `DataFrames` is one of the key operations you will do all the time, so it is better to get it clearly. Let's start with the `Series`. We already showed that index can be non-integer, e.g. it can be composed of strings:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And you can slice with this (*explicit*) indexing:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# slicing by explicit index\n",
    "data['b':'d']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But `Series` also allows you to slice based on elements posision, which is called *implicit* indexing:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# slicing by implicit integer index\n",
    "data[1:4]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This can create confusion if your index is integer, but not continuos, e.g. [2,4,6,8,10], etc. This is resolved in the next section.\n",
    "\n",
    "\n",
    "## Boolean indexing\n",
    "A particular type of indexing is *boolean* indexing, sometimes also called *masking*. It happens when instead of an index you're passing a set of `bool` values (e.g. an array, or a `Series`), which has to be the same size as the object you're trying to index. In this case you're getting only those values, which corresponded to the `True` values in the boolean array. This comes up very frequently, and it is a very useful type of indexing, because if allows you to *filter* values based on certain criteria. In the following example I only want values which are larger than `0.6`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# this creates a boolean *mask* which has True only when values > 0.3\n",
    "data > 0.6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# I use this mask to get the corresponding values\n",
    "data[data > 0.3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">**Pro-tip**: You can also combine several conditions in the same line by using `&` operator, which implements an element-wise logical AND, e.g.:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "(data > 0.3) & (data < 0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# masking\n",
    "data[(data > 0.3) & (data < 0.8)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Stick `|` implements logical OR:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data[(data < 0.3) | (data > 0.8)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> These 2 and other logical operations can also be called using `numpy` functions, e.g. `(data > 0.3) & (data < 0.8)` is equivalent to `np.logical_and(data > 0.3, data < 0.8)`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# using logical OR as a function\n",
    "np.logical_or(data < 0.3, data > 0.8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Avoiding confusion between explicit and implicit indexing\n",
    "As was pointed out in the previous section, having an explicit and an implicit indexing can create confusion, especially if you have integer index. Let's see it in practice:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data = pd.Series(['a', 'b', 'c', 'e', 'f', 'g'], index=[1, 3, 5, 7, 9, 11])\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When you retrieve elements, explicit index is used by default:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# explicit index is used by default when indexing \n",
    "data[3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But when you do slicing, it uses implicit indexing, so `[:3]` returns first 3 elements, instead of elements up to with `index` 3:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# implicit index by default when slicing\n",
    "data[:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is no good -- can lead to errors. To avoid these and explicitly use either of two types of indexes, `pandas` `Series` and `DataFrames` have attributes `.loc` (for explicit indexing) and `.iloc` (for implicit indexing). Let's see a couple of examples:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "data.loc[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data.loc[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data.iloc[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data.iloc[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "states"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "states.loc['California']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "states.iloc[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can also specify both dimensions and extract different elements:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "states.loc['California','population']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "states.iloc[0,1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# In case of `DataFrames`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "states"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "states['area']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "states['density'] = states['population'] / states['area']\n",
    "states"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "states.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "states.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "states.iloc[:3, :2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "states.loc[:'Illinois', :'population']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the end the fact that you can use implicit indexing (`.iloc`) doesn't mean that you should. In reality, explicit indexing is the one you use most of the time."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <font color='DarkSeaGreen '>Exercise</font>\n",
    "In the cell(s) below, from  the `DataFrame` with days of the week:\n",
    "1. Extract row with index 3\n",
    "2. Extract value `Saturday`\n",
    "3. Extract column (as `Series`) with status of the days (workday or weekend)\n",
    "4. It is the week after Pasqua! Change work status of Monday to 'Holiday'\n",
    "5. Make new column with encodes work-status of the days as `bool` (`True` for workdays and `False` for weekends and holidays); set the name of this column `come_to_SISSA`\n",
    "6. Using `.iloc`, extract the last 3 values of the `come_to_SISSA` column\n",
    "7. Using `boolean` indexing, extract names of the day of the week where `come_to_SISSA` is `True`\n",
    "8. Same as previous, but when `come_to_SISSA` is `False`\n",
    "\n",
    "Optional. In the `DataFrame` with days of the month:\n",
    "1. Set values of the following days to 'Holiday': 14, 17, 24, 25\n",
    "2. Make new column with encodes work-status of the days as `bool` (`True` for workdays and `False` for weekends and holidays); set the name of this column `come_to_SISSA`\n",
    "3. Using `.iloc`, extract the last 3 row of the `DataFrame`\n",
    "4. Using `boolean` indexing, extract names of the day of the week where `come_to_SISSA` is `False` "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Operations on `Series` and `DataFrame`\n",
    "Operations on `DataFrames` and `Series` will preserve the `index`, even if the order is different, example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "a = pd.Series({0:10, 1:20, 2: 30})\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "b = pd.Series({0:1, 1:2, 2: 3})[::-1]\n",
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "a/b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If some of the indexes exist in one, but not the other `Series`, it will give you `NaN`, *Not a Number*, as a result:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "area = pd.Series({'Alaska': 1723337, \n",
    "                  'Texas': 695662,\n",
    "                  'California': 423967}, name='area')\n",
    "\n",
    "population = pd.Series({'California': 38332521, \n",
    "                        'Texas': 26448193,\n",
    "                        'New York': 19651127}, name='population')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "population / area"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "A = pd.Series([2, 4, 6], index=[0, 1, 2])\n",
    "B = pd.Series([1, 3, 5], index=[1, 2, 3])\n",
    "A + B"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This simplifies working on complex data A LOT, because you don't have to worry that all the values are in the same positions in all of your tables or columns, you just need to know that the labels (indexes) are consistent.\n",
    "\n",
    "Another example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "A = pd.DataFrame(np.random.randint(0, 20, (2, 2)),\n",
    "                 columns=list('AB'))\n",
    "A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "B = pd.DataFrame(np.random.randint(0, 10, (3, 3)),\n",
    "                 columns=list('BAC'))\n",
    "B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "A + B"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sometimes you might want to do operations not element-wise, but columns-wise, or row-wise, for example, if you want to subtract values in one row from all rows. `pandas` can handle this automatically:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df = pd.DataFrame(np.random.randint(10, size=(3, 4)), columns=list('QRST'))\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By default, it will work fine with rows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df - df.loc[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But if you try columns, you'll get something weird:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df - df['R']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Of course, there is a logical explanation for why this happens, and it has to do with `pandas` not understanding which axis you want to match. It tries to match `index` of `df['R']` with `columns` of `df` and doesn't find any correspondence between the two. To avoid this, you need to specify the axis explicitly. In this case you'd have to use method `subtract`, like so:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df.subtract(df['R'], axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Keeping consistency with its matching principles, it you subtract a `Series` which contains only some indexes, it will only return you values for the corresponding columns:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# getting second row, and ever second column\n",
    "halfrow = df.iloc[0, ::2]\n",
    "halfrow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df - halfrow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Handling missing data\n",
    "Missing data is an big problem and can be a pain to handle. In `pandas` there are special tools for dealing with missing data. First, what is considered a missing value? It is either `None` or `np.nan`. `None` is an in-build special Python class, which you can use in any context to specify a missing value, but the problem is that it is not optimized for numerical computations, because it doesn't belong to any specific numerical class. Therefore, if you put it in an array, it will automatically make `dtype=object`, which is the most general `dtype` (can include anything) and doesn't offer speed advantages of numerical arrays. In comparison, `np.nan` actually belongs to the class `float64` and is specifically designed to occupy the same memory space as `float64` and not hurdle the computations. Demonstration:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "vals = np.array([1, None, 3, 4])\n",
    "vals.dtype # dtype('O') means `object`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "vals = np.array([1, np.nan, 3, 4])\n",
    "vals.dtype"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Just to see how much `dtype=object` hurts as, let's create two arrays, which contain the same values (numbers from 0 to 10^6), first with `dtype=object` and second with `dtype=int`, and time how much it takes to compute sum of all elements.\n",
    "\n",
    ">**Note**: `1E6` is a shortcut for `1 * 10**6`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for dtype in ['object', 'int']:\n",
    "    print(\"dtype =\", dtype)\n",
    "    %timeit np.arange(1E6, dtype=dtype).sum()\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Same data, but with `dtype=object` it takes ~30 times longer to compute the sum. So we don't want to use `None` in any kind of settings, where we intend to do numerical computations, we always use `np.nan`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "vals2 = np.array([1, np.nan, 3, 4]) \n",
    "vals2.dtype"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you try to do operations with `NaN`, it will give `NaN` as a result. Same as if you try to use standard aggregation functions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "1 + np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "vals2.sum(), vals2.min(), vals2.max()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To handle `nan` there are special `numpy` functions which ignore `nan`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "np.nansum(vals2), np.nanmin(vals2), np.nanmax(vals2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "However, in `pandas` this is all simplified. First, both `None` and `np.nan` will become `NaN` in `pandas` (if you have numerical `Series`, otherwise see **side note** below), so you don't have to worry about having `None` somewhere:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "x = pd.Series([1, np.nan, 2, None])\n",
    "x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Second missing values are ignored by default, because they are frequent in data analysis and we don't want to use special functions all the time:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "x.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "x.sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">**Side note**: If you have numerical `Series`, `pandas` will change `None` to `np.nan`. However, if you have a `Series` with `dtype=object` (`Series` which can contain anything, but doesn't offer numerical advantage), it will not change by default:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data = pd.Series([1, np.nan, 'hello', None])\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> This is not a problem, because methods for working with missing values we will learn below will work with both `nan` and `None`. They do not discriminate."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are also several methods to deal specifically with `NaN` values:\n",
    "\n",
    "- `isnull()`: Generate a boolean mask indicating missing values\n",
    "- `notnull()`: Opposite of `isnull()`\n",
    "- `dropna()`: Return a filtered version of the data\n",
    "- `fillna()`: Return a copy of the data with missing values filled or imputed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data = pd.Series([1, np.nan, 'hello', None])\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data.isnull()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data[data.notnull()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df = pd.DataFrame([[1,      np.nan, 2],\n",
    "                   [2,      3,      5],\n",
    "                   [np.nan, 4,      6]])\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you `dropna()`, by default it will drop all rows which contain at least 1 `nan` value:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df.dropna()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But you can specify axis (`'rows'` or `'columns'`, which is the same as `0` and `1`):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df.dropna(axis='columns')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can also specify to throw away columns or rows only if all values are `nan`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df[3] = np.nan\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df.dropna(axis='columns', how='all')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filling null values\n",
    "Sometimes you don't want to throw away missing values, but intead you want to fill them with some other values. There a method `fillna()` for this, and it has parameters which help you specify the filling rule:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data = pd.Series([1, np.nan, 2, None, 3], index=list('abcde'))\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can fill with a certain values (e.g., `0`):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data.fillna(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Or you can fill each `nan` with the previous existing values (forward fill):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# forward-fill\n",
    "data.fillna(method='ffill')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Or with the next existing value (backward fill):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# back-fill\n",
    "data.fillna(method='bfill')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For `DataFrames` you can also specify which axis to do filling from (by default it is rows, meaning that it takes from the previous row in the same column):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df.fillna(method='ffill')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you specify `axis=1` (or `axis='columns'` which is the same), it will take from the same row, but from the previous (`ffill`) or next (`bfill`) column:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df.fillna(method='ffill', axis='columns')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <font color='DarkSeaGreen '>Exercise</font>\n",
    "In the cell(s) below, in the `DataFrame` with days of the week:\n",
    "1. Create a new column 'lesson_duration_min' with all values = np.nan\n",
    "2. Set the following values in this column: for Tuesday -- 120, Wednesday -- 120+150, Thursday -- 120, Friday -- 120+150\n",
    "2. Calculate mean duration of the lessons next week.\n",
    "2. Calculate total number of class hours for the next week.\n",
    "3. Using the new column, get the names of the days of the week when there is no lesson\n",
    "4. Using `fillna` change values of `nan` to `0`\n",
    "\n",
    "Optional: \n",
    "1. Create 'lesson_duration_min' for the days of the month `DataFrame`, except don't put values of duration in every cell separately, but set all Wednesdays and Fridays to 120+150 and all Tuesdays and Thursdays to 120.\n",
    "2. In every row which is not a 'Workday' set duration to 0.\n",
    "2. Calculate mean duration of the lessons for the month.\n",
    "2. Calculate total number of class hours for the month."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.6",
   "language": "python",
   "name": "py36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
